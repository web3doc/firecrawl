---
title: 'Python'
description: 'Firecrawl Python SDK 是 Firecrawl API 的包装器，帮助你轻松将网站转换为 Markdown。'
icon: 'python'
og:title: "Python SDK | Firecrawl"
og:description: "Firecrawl Python SDK 是 Firecrawl API 的包装器，帮助你轻松将网站转换为 Markdown。"
---

import InstallationPython from '/snippets/v1/installation/python.mdx'
import ScrapePythonShort from '/snippets/v1/scrape/short/python.mdx'
import CrawlPythonShort from '/snippets/v1/crawl/short/python.mdx'
import CheckCrawlStatusPythonShort from '/snippets/v1/crawl-status/short/python.mdx'
import CrawlAsyncPythonShort from '/snippets/v1/crawl-async/short/python.mdx'
import CancelCrawlPythonShort from '/snippets/v1/crawl-delete/short/python.mdx'
import MapPythonShort from '/snippets/v1/map/short/python.mdx'
import ExtractPythonShort from '/snippets/v1/extract/short/python.mdx'
import ScrapeAndCrawlExamplePython from '/snippets/v1/scrape-and-crawl/python.mdx'
import CrawlWebSocketPythonBase from '/snippets/v1/crawl-websocket/base/python.mdx'

## 安装

要安装 Firecrawl Python SDK，可以使用 pip：

<InstallationPython />

## 使用

1. 从 [firecrawl.dev](https://firecrawl.dev) 获取一个 API 密钥
2. 将 API 密钥设置为名为 `FIRECRAWL_API_KEY` 的环境变量，或者将其作为参数传递给 `FirecrawlApp` 类。


以下是一个如何使用 SDK 的示例：

<ScrapeAndCrawlExamplePython />

### 抓取 URL

要抓取单个 URL，请使用 `scrape_url` 方法。它接受 URL 作为参数，并返回抓取到的数据作为字典。

<ScrapePythonShort />

### 爬取网站

要爬取网站，请使用 `crawl_url` 方法。它接受起始 URL 和可选参数作为参数。`params` 参数允许你指定爬取作业的其他选项，例如要爬取的最大页面数、允许的域和输出格式。

<CrawlPythonShort />

### 异步爬取

要异步爬取网站，请使用 `crawl_url_async` 方法。它返回爬取作业的 `ID`，你可以用它来检查爬取作业的状态。它接受起始 URL 和可选参数作为参数。`params` 参数允许你指定爬取作业的其他选项，例如要爬取的最大页面数、允许的域和输出格式。

<CrawlAsyncPythonShort />


### 检查爬取状态

要检查爬取作业的状态，请使用 `check_crawl_status` 方法。它接受作业 ID 作为参数，并返回爬取作业的当前状态。

<CheckCrawlStatusPythonShort />

### 取消爬取

要取消异步爬取作业，请使用 `cancel_crawl` 方法。它接受异步爬取作业的作业 ID 作为参数，并返回取消状态。

<CancelCrawlPythonShort />

### 绘制网站图

使用 `map_url` 生成网站的 URL 列表。`params` 参数允许你自定义绘图过程，包括排除子域或利用站点地图的选项。

<MapPythonShort />

{/* ### 从网站中提取结构化数据

要从网站中提取结构化数据，请使用 `extract` 方法。它接受要提取数据的 URL、提示和架构作为参数。架构是一个 Pydantic 模型，定义了提取数据的结构。

<ExtractPythonShort /> */}

### 使用 WebSockets 爬取网站

要使用 WebSockets 爬取网站，请使用 `crawl_url_and_watch` 方法。它接受起始 URL 和可选参数作为参数。`params` 参数允许你指定爬取作业的其他选项，例如要爬取的最大页面数、允许的域和输出格式。


<CrawlWebSocketPythonBase />

## 错误处理

SDK 处理 Firecrawl API 返回的错误并抛出适当的异常。如果请求过程中发生错误，将会抛出带有描述性错误消息的异常。