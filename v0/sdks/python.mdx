---
title: 'Python'
description: 'Firecrawl Python SDK 是 Firecrawl API 的封装，帮助您轻松将网站转换为 Markdown。'
icon: 'python'
og:title: "Python SDK | Firecrawl"
og:description: "Firecrawl Python SDK 是 Firecrawl API 的封装，帮助您轻松将网站转换为 Markdown。"
---

> 注意：这是使用已弃用的 [Firecrawl API v0 版本](/v0/introduction)。我们建议切换到 [v1](/sdks/python)。

## 安装

要安装 Firecrawl Python SDK，可以使用 pip：

```bash
pip install firecrawl-py==0.0.16
```

## 使用

1. 从 [firecrawl.dev](https://firecrawl.dev) 获取 API 密钥。
2. 将 API 密钥设置为环境变量 `FIRECRAWL_API_KEY`，或将其作为参数传递给 `FirecrawlApp` 类。

以下是如何使用 SDK 的示例：

```python
from firecrawl import FirecrawlApp

# 使用您的 API 密钥初始化 FirecrawlApp
app = FirecrawlApp(api_key='your_api_key')

# 抓取单个 URL
url = 'https://docs.firecrawl.dev'
scraped_data = app.scrape_url(url)

# 爬取网站
crawl_url = 'https://docs.firecrawl.dev'
params = {
    'pageOptions': {
        'onlyMainContent': True
    }
}
crawl_result = app.crawl_url(crawl_url, params=params)
```

### 抓取 URL

要抓取单个 URL，请使用 `scrape_url` 方法。它接受 URL 作为参数，并返回抓取的数据作为字典。

```python
url = 'https://example.com'
scraped_data = app.scrape_url(url)
```

### 从 URL 提取结构化数据

使用 LLM 提取，您可以轻松地从任何 URL 中提取结构化数据。我们支持 pydantic 模式，以使操作更加简便。以下是使用方法：

```python
class ArticleSchema(BaseModel):
    title: str
    points: int 
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., max_items=5, description="Top 5 stories")

data = app.scrape_url('https://news.ycombinator.com', {
    'extractorOptions': {
        'extractionSchema': TopArticlesSchema.model_json_schema(),
        'mode': 'llm-extraction'
    },
    'pageOptions':{
        'onlyMainContent': True
    }
})
print(data["llm_extraction"])
```

### 爬取网站

要爬取网站，请使用 `crawl_url` 方法。它接受起始 URL 和可选参数作为参数。`params` 参数允许您指定爬取作业的其他选项，如最大页面数、允许的域名以及输出格式。

`wait_until_done` 参数决定该方法是否应等待爬取作业完成再返回结果。如果设置为 `True`，该方法将定期检查爬取作业的状态，直到完成或达到指定的 `timeout`（秒）。如果设置为 `False`，该方法将立即返回作业 ID，您可以手动使用 `check_crawl_status` 方法检查爬取作业的状态。


```python
crawl_url = 'https://example.com'
params = {
    'crawlerOptions': {
        'excludes': ['blog/*'],
        'includes': [], # 留空表示所有页面
        'limit': 1000,
    },
    'pageOptions': {
        'onlyMainContent': True
    }
}
crawl_result = app.crawl_url(crawl_url, params=params, wait_until_done=True, timeout=5)
```

如果 `wait_until_done` 设置为 `True`，`crawl_url` 方法将在作业完成后返回爬取结果。如果作业失败或停止，将引发异常。


### 检查爬取状态

要检查爬取作业的状态，请使用 `check_crawl_status` 方法。它接受作业 ID 作为参数，并返回当前爬取作业的状态。

```python
job_id = crawl_result['jobId']
status = app.check_crawl_status(job_id)
```

### 搜索查询

用于搜索网络，获取最相关的结果，抓取每个页面并返回 Markdown。

```python
query = 'what is mendable?'
search_result = app.search(query)
```

## 错误处理

SDK 处理 Firecrawl API 返回的错误，并引发适当的异常。如果在请求期间发生错误，将引发带有描述性错误消息的异常。