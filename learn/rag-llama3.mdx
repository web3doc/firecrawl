---
标题: "使用 Groq Llama 3 构建 '与网站聊天'"
描述: "学习如何使用 Firecrawl、Groq Llama 3 和 Langchain 构建一个 '与您的网站聊天' 机器人。"
og:title: "使用 Groq Llama 3 构建 '与网站聊天' | Firecrawl"
og:description: "学习如何使用 Firecrawl、Groq Llama 3 和 Langchain 构建一个 '与您的网站聊天' 机器人。"
---

> 注意：此示例使用的是 [Firecrawl API 的 v0 版本](/v0/introduction)。你可以安装 Python SDK 的 0.0.20 版本或 Node SDK 的 0.0.36 版本。

## 设置

安装我们的 Python 依赖，包括 langchain、groq、faiss、ollama 和 firecrawl-py。

```bash
pip install --upgrade --quiet langchain langchain-community groq faiss-cpu ollama firecrawl-py
```

我们将使用 Ollama 进行嵌入，你可以在这里下载 Ollama [链接](https://ollama.com/)。但是你也可以自由使用任何你喜欢的其他嵌入。

## 使用 Firecrawl 加载网站

为了能够从网站获取所有数据并确保其格式最干净，我们将使用 Firecrawl。Firecrawl 可以非常轻松地与 Langchain 集成作为文档加载器。

以下是如何使用 Firecrawl 加载网站的方法：

```python
from langchain_community.document_loaders import FireCrawlLoader  # 导入 FireCrawlLoader

url = "https://firecrawl.dev"
loader = FireCrawlLoader(
    api_key="fc-YOUR_API_KEY", # 注意：将 'YOUR_API_KEY' 替换为你的实际 FireCrawl API 密钥
    url=url,  # 要抓取的目标 URL
    mode="crawl"  # 模式设置为 'crawl' 以抓取所有可访问的子页面
)
docs = loader.load()
```

## 设置向量存储库

接下来，我们将设置向量存储库。向量存储库是一种数据结构，允许我们存储和查询嵌入。我们将使用 Ollama 嵌入和 FAISS 向量存储库。
我们将文档分割成每块 1000 个字符，重叠 200 个字符。这是为了确保块既不会太小也不会太大——并且在我们查询时能够适应 LLM 模型。

```python
from langchain_community.embeddings import OllamaEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
vectorstore = FAISS.from_documents(documents=splits, embedding=OllamaEmbeddings())
```

## 检索和生成

现在文档已经加载并且向量存储库已设置好，我们可以基于用户的问题进行相似性搜索以检索最相关的文档。这样我们就可以将这些文档提供给 LLM 模型。

```python
question = "什么是 firecrawl?"
docs = vectorstore.similarity_search(query=question)
```

## 生成

最后但同样重要的是，你可以使用 Groq 根据我们加载的文档生成对问题的响应。

```python
from groq import Groq

client = Groq(
    api_key="YOUR_GROQ_API_KEY",
)

completion = client.chat.completions.create(
    model="llama3-8b-8192",
    messages=[
        {
            "role": "user",
            "content": f"你是一个友好的助手。你的工作是根据以下提供的文档回答用户的问题:
文档:

{docs}

问题: {question}"
        }
    ],
    temperature=1,
    max_tokens=1024,
    top_p=1,
    stream=False,
    stop=None,
)

print(completion.choices[0].message)
```

## 大功告成！

你现在已经使用 Llama 3、Groq Llama 3、Langchain 和 Firecrawl 构建了一个 '与您的网站聊天' 机器人。你现在可以使用这个机器人基于你网站的文档来回答问题了。

如果你有任何问题或需要帮助，请随时通过 [Firecrawl](https://firecrawl.dev) 联系我们。