---
title: "使用LLM提取客户洞察"
description: "使用LLM提取洞察和潜在客户生成，利用Make和Firecrawl。"
og:title: "使用LLM提取客户洞察 | Firecrawl"
og:description: "使用LLM提取洞察和潜在客户生成，利用Make和Firecrawl。"
---

> 注意：此示例使用了[Firecrawl API的v0版本](/v0/introduction)。您可以安装Python SDK的0.0.20版本或Node SDK的0.0.36版本。

### 引言

了解我们的客户——不仅仅是他们是谁，还有他们做什么——对于有效地定制我们的产品与服务至关重要。在自助服务模式中，您会遇到许多对您知之甚少的客户。主动了解这些人的过程传统上是耗时的，涉及手动数据收集和分析以获取可行的见解。

然而，借助大型语言模型（LLMs）的力量及其高级数据提取能力，我们已将这一过程自动化。通过使用LLM提取和分析客户数据，我们显著减轻了工作负担，使我们能够比以前更有效地理解和服务于我们的客户群。

如果您的技术知识有限，您可以构建一个自动化工具，以获取有关您的客户的针对性信息，用于产品方向和潜在客户生成。以下是如何使用[Make](https://make.com/)和[Firecrawl](https://www.firecrawl.dev/)来实现这一点的方法。

---

### 工具概述

**Firecrawl**

Firecrawl是一个用于抓取、搜索和提取的平台。它允许您从网络获取数据并将其转换为LLM可读的Markdown或结构化数据。

当我们想要获取关于我们客户的信息时，我们可以使用Firecrawl的LLM提取功能来指定我们希望从他们的网站获取的具体信息。

**Make.com（前身为Integromat）**

Make是一个自动化平台，允许用户创建自定义工作流程以连接各种应用程序和服务，而无需深厚的技术知识。它使用一个可视化界面，用户可以在其中拖放元素来设计他们的自动化流程。

我们可以使用Make将用户数据的电子表格连接到Firecrawl，只需一点JSON即可进行提取。

### 设置场景

- 逐步指南，用于设置数据提取过程。
- **将Google Sheets连接到Make.com**
  - 如何初步收集和存储用户数据。
- **在Make.com中配置HTTP请求**
  - 设置API请求到Firecrawl的描述。
  - 这些请求的目的（例如，提取公司信息）。

### 准备我们的数据

在我们开始之前，我们想确保为Firecrawl准备好我们的数据。在这个案例中，我创建了一个包含从我们的数据库导入的用户简单电子表格。我们想获取用户的电子邮件域名，并将它们转换为使用https://格式的链接：

![](https://i.imgur.com/gssynZa.png)

我们还想添加一些我们希望了解的公司的属性。对我来说，我想了解一下公司、它们的行业以及它们的客户。我在列中设置了这些属性：
company_description
company_type
who_they_serve

现在我们的数据准备好了，我们可以开始在Make中设置我们的自动化流程了！

## 设置我们的自动化流程

要让我们自动化运行，我们只需在Make中遵循一个简单的三步过程。在这里，我们将选择我们场景中的三个应用程序：

Google Sheets - 获取范围值
HTTP - 制作API密钥认证请求
Google Sheets - 更新一行

我们还将添加忽略流控制工具，以防遇到任何错误。这将保持自动化的运行。

![](https://i.imgur.com/MdCWv30.png)

这个自动化将允许我们从电子表格中提取一组链接，将它们发送到Firecrawl进行数据提取，然后用所需的信息重新填充我们的电子表格。

首先，我们配置我们的第一个应用程序。我们的目标是导出所有的URL，以便我们可以将它们发送到Firecrawl进行提取。以下是拉取这些URL的配置：

![](https://i.imgur.com/WHa91kY.png)

\*_重要提示_ - 我们想确保我们从第二行开始拉取数据。如果你包括标题行，你最终会遇到错误。

---

太好了！现在我们已经配置好了，我们准备设置我们的HTTP请求。为此，我们将前往https://firecrawl.dev注册并获取我们的API密钥（你可以免费开始！）。注册后，你可以前往https://firecrawl.dev/account查看你的API密钥。


我们将使用Firecrawl的Scrape端点。这个端点将允许我们从单个URL拉取信息，将其转换为干净的Markdown，并用它来提取我们需要的数据。我将使用他们的文档中的API参考来填写Make HTTP请求中的所有必要条件。


现在在Make中，我使用Firecrawl的文档来配置API调用。我们将使用POST作为HTTP方法，并有两个头信息。


```
Header 1:
Name: Authorization
Value: Bearer your-API-key

Header 2:
Name: Content-Type
Value: application/json
```

![](https://i.imgur.com/LJ8g142.png)
我们还想设置我们的正文和内容类型。在这里，我们将这样做：

```
Body type: Raw
Content type: Json (application/json)
```

我们还将点击“是”以解析我们的响应。这将自动将我们的响应解析为JSON。

请求内容是我们想要实现的主要部分。以下是我们将用于此用例的请求内容：

```
{
  "url": "1. url(B)",

"pageOptions": {
    "onlyMainContent": true
  },
  "extractorOptions": {
    "mode": "llm-extraction",
    "extractionPrompt": "Extract the company description (in one sentence explain what the company does), company industry (software, services, AI, etc.) - this really should just be a tag with a couple keywords, and who they serve (who are their customers). If there is no clear information to answer the question, write 'no info'.",
    "extractionSchema": {
      "type": "object",
      "properties": {
        "company_description": {
          "type": "string"
        },
        "company_industry": {
          "type": "string"
        },
        "who_they_serve": {
          "type": "string"
        }
      },
      "required": [
        "company_description",
        "company_industry",
        "who_they_serve"
      ]
    }
  }
}
```

![](https://i.imgur.com/DrMc1g2.png)

\*_注意_ 截图中的绿色字段是一个你可以在Make UI中选择的动态项。而不是`url (B)`，该块可能是你的数据中的第一个URL。


![](https://i.imgur.com/D4HCBNe.png)

太棒了！现在我们已经配置好了HTTP请求。让我们测试一下，确保一切按预期工作。在Make中点击“运行一次”，我们应该会收到数据返回。

![](https://i.imgur.com/QuQZs0U.png)

当我们运行时，让我们检查我们的第一个操作。在输出中，我们应该得到一个`状态码: 200`，这意味着我们的API请求成功了。在输出中，点击数据以确保我们得到了所需的数据。

![](https://i.imgur.com/pm614VA.png)

我们的输出看起来很成功！在llm_extraction中，我们看到我们想要从网站获取的三个属性的数据。


\*_注意_ 如果你的第一个操作出现`500`错误，而后续的操作返回`200`响应，这可能是因为操作试图在你的数据的第一行（标题行）上执行。这将导致问题，因为无法将数据重新导入到表格中！确保如前所述从第二行开始。
现在我们知道HTTP请求工作正常，剩下的就是将Firecrawl输出的JSON放回我们的电子表格中。

---

现在我们需要将我们提取的数据放回电子表格中。为此，我们将从HTTP请求中输出的JSON中提取文本，并将其导出到相关表格中。

让我们从连接相同的Google表格开始，并指定行号标准。在这里，我们将仅使用Make UI来选择“行号”

![](https://i.imgur.com/BYpPabk.png)

剩下的就是指定哪些LLM提取的数据进入哪个列。在这里，我们可以简单地使用Make中的UI来进行设置。
![](https://i.imgur.com/219tft2.png)

就这样，现在是时候测试我们的自动化流程了！
---

让我们在Make UI上点击“运行一次”，并确保一切运行顺畅。自动化应该开始逐个链接迭代，并实时填充我们的电子表格。
![](https://i.imgur.com/vU1CJlt.png)

我们成功了！使用Make和Firecrawl，我们能够提取有关我们客户的特定信息，而无需手动访问他们的每个网站。

查看数据，我们开始更好地了解我们的客户。然而，我们并不仅限于这些具体特征。如果需要，