---
title: '爬取'
description: 'Firecrawl 可以递归地搜索 URL 的子域名，并收集内容。'
og:title: "爬取 | Firecrawl"
icon: "spider"
og:description: "Firecrawl 可以递归地搜索 URL 的子域名，并收集内容。"
---

import InstallationPython from "/snippets/v1/installation/python.mdx";
import InstallationNode from "/snippets/v1/installation/js.mdx";
import InstallationGo from "/snippets/v1/installation/go.mdx";
import InstallationRust from "/snippets/v1/installation/rust.mdx";
import CrawlPython from "/snippets/v1/crawl/base/python.mdx";
import CrawlNode from "/snippets/v1/crawl/base/js.mdx";
import CrawlGo from "/snippets/v1/crawl/base/go.mdx";
import CrawlRust from "/snippets/v1/crawl/base/rust.mdx";
import CrawlCURL from "/snippets/v1/crawl/base/curl.mdx";
import AsyncCrawlOutput from "/snippets/v1/crawl-async/base/output.mdx";
import CheckCrawlJobPython from "/snippets/v1/crawl-status/short/python.mdx";
import CheckCrawlJobNode from "/snippets/v1/crawl-status/short/js.mdx";
import CheckCrawlJobGo from "/snippets/v1/crawl-status/short/go.mdx";
import CheckCrawlJobRust from "/snippets/v1/crawl-status/short/rust.mdx";
import CheckCrawlJobCURL from "/snippets/v1/crawl-status/short/curl.mdx";
import CheckCrawlJobOutputScraping from "/snippets/v1/crawl-status/base/output-scraping.mdx";
import CheckCrawlJobOutputCompleted from "/snippets/v1/crawl-status/base/output-completed.mdx";
import CrawlWebSocketPython from "/snippets/v1/crawl-websocket/base/python.mdx";
import CrawlWebSocketNode from "/snippets/v1/crawl-websocket/base/js.mdx";
import CrawlWebhookCURL from "/snippets/v1/crawl-webhook/base/curl.mdx";

Firecrawl 彻底爬取网站，确保全面的数据提取，同时绕过任何网络阻止机制。其工作原理如下：

1. **URL 分析**:
   从一个指定的 URL 开始，通过查看站点地图来识别链接，然后爬取网站。如果没有找到站点地图，它将按照链接爬取网站。

2. **递归遍历**:
   递归地跟随每个链接以发现所有子页面。

3. **内容抓取**:
   从每个访问过的页面中收集内容，同时处理诸如 JavaScript 渲染或速率限制等复杂性。

4. **结果编译**:
   将收集到的数据转换为干净的 markdown 或结构化输出，非常适合 LLM 处理或其他任务。

此方法保证了从任何起始 URL 进行彻底的爬取和数据收集。

## 爬取

### /crawl 端点

用于爬取一个 URL 及其所有可访问的子页面。这提交了一个爬取作业，并返回一个作业 ID，用于检查爬取状态。

<Warning>默认情况下 - 如果子链接不是您提供的 URL 的子节点，爬取将忽略这些子链接。因此，如果您爬取 website.com/blogs/，则不会返回 website.com/other-parent/blog-1。如果您需要 website.com/other-parent/blog-1，请使用 `allowBackwardLinks` 参数。</Warning>

### 安装 

<CodeGroup>

<InstallationPython />
<InstallationNode />
<InstallationGo />
<InstallationRust />

</CodeGroup>

### 用法

<CodeGroup>

<CrawlPython />
<CrawlNode />
<CrawlGo />
<CrawlRust />
<CrawlCURL />

</CodeGroup>

### 响应

如果您正在使用 cURL 或 SDK 上的 `async crawl` 函数，这将返回一个 `ID`，您可以使用它来检查爬取的状态。

<AsyncCrawlOutput />

### 检查爬取作业

用于检查爬取作业的状态并获取其结果。

<Note>此端点仅适用于正在进行中的爬取或最近完成的爬取。</Note>

<CodeGroup>

<CheckCrawlJobPython />
<CheckCrawlJobNode />
<CheckCrawlJobGo />
<CheckCrawlJobRust />
<CheckCrawlJobCURL />

</CodeGroup>

#### 响应处理

根据爬取的状态，响应会有所不同。

对于未完成或超过 10MB 的大型响应，会提供一个 `next` URL 参数。您必须请求此 URL 以检索下一组 10MB 的数据。如果缺少 `next` 参数，则表示爬取数据的结束。


skip 参数设置了每次返回的结果块的最大数量。 

<Info>
当直接调用 API 时，skip 和 next 参数才相关。如果您使用的是 SDK，我们会为您处理这些，并将一次性返回所有结果。
</Info>

<CodeGroup>
<CheckCrawlJobOutputScraping />
<CheckCrawlJobOutputCompleted />
</CodeGroup>

## 爬取 WebSocket

Firecrawl 基于 WebSocket 的方法“爬取 URL 并监控”实现了实时数据提取和监控。使用一个 URL 启动爬取，并通过选项（如页面限制、允许的域名和输出格式）进行自定义，非常适合于即时数据处理需求。


<CodeGroup>
<CrawlWebSocketPython />
<CrawlWebSocketNode />
</CodeGroup>

## 爬取 Webhook

现在可以将 `webhook` 参数传递给 `/crawl` 端点。这将在爬取开始、更新和完成时向指定的 URL 发送 POST 请求。

Webhook 现在将对每个爬取的页面触发，而不仅仅是在最后整个结果结束时触发。


<CrawlWebhookCURL />

### Webhook 事件

现在有四种类型的事件：

- `crawl.started` - 当爬取开始时触发。
- `crawl.page` - 对每个爬取的页面触发。
- `crawl.completed` - 当爬取完成时触发，让您知道它已完成（Beta）。**
- `crawl.failed` - 当爬取失败时触发。


### Webhook 响应

- `success` - 如果 webhook 成功爬取页面。
- `type` - 发生的事件类型。
- `id` - 爬取的 ID。
- `data` - 被抓取的数据（数组）。这仅在 `crawl.page` 上非空，并且如果页面被成功抓取，将包含一个项目。响应与 `/scrape` 端点的响应相同。
- `error` - 如果 webhook 失败，这将包含错误消息。


**Beta 注意事项**

- 存在极小的可能性，即 `crawl.completed` 事件可能在最后的 `crawl.page` 事件仍在处理时被触发。我们正在修复这个问题。