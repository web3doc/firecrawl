---
title: "批量抓取"
description: "批量抓取多个URLs"
og:title: "批量抓取 | Firecrawl"
og:description: "批量抓取多个URLs"
---

import BatchScrapePython from "/snippets/v1/batch-scrape/base/python.mdx";
import BatchScrapeNode from "/snippets/v1/batch-scrape/base/js.mdx";
import BatchScrapeCURL from "/snippets/v1/batch-scrape/base/curl.mdx";
import BatchScrapeOutput from "/snippets/v1/batch-scrape/base/output.mdx";
import BatchScrapeAsyncOutput from "/snippets/v1/batch-scrape/base/async-output.mdx";
import BatchScrapeExtractPython from "/snippets/v1/batch-scrape/extract/python.mdx";
import BatchScrapeExtractNode from "/snippets/v1/batch-scrape/extract/js.mdx";
import BatchScrapeExtractCURL from "/snippets/v1/batch-scrape/extract/curl.mdx";
import BatchScrapeExtractOutput from "/snippets/v1/batch-scrape/extract/output.mdx";
import BatchScrapeExtractAsyncOutput from "/snippets/v1/batch-scrape/extract/async-output.mdx";

## 批量抓取多个URLs

你现在可以同时批量抓取多个URL。它接受起始URL和可选参数作为参数。params参数允许你指定批量抓取作业的额外选项，例如输出格式。

### 工作原理

它与 `/crawl` 端点的工作方式非常相似。它提交一个批量抓取作业并返回一个作业ID，用于检查批量抓取的状态。

SDK提供了两种方法，同步和异步。同步方法将返回批量抓取作业的结果，而异步方法将返回一个作业ID，你可以使用该ID来检查批量抓取的状态。

### 使用方法

<CodeGroup>

<BatchScrapePython />
<BatchScrapeNode />
<BatchScrapeCURL />

</CodeGroup>

### 响应

如果你使用的是SDK的同步方法，它将返回批量抓取作业的结果。否则，它将返回一个作业ID，你可以使用该ID来检查批量抓取的状态。

#### 同步

<BatchScrapeOutput />

#### 异步

然后你可以使用作业ID通过调用 `/batch/scrape/{id}` 端点来检查批量抓取的状态。这个端点应在作业仍在运行时或在作业刚刚完成后使用 **因为批量抓取作业会在24小时后过期**。

<BatchScrapeAsyncOutput />

## 带提取的批量抓取

你也可以使用批量抓取端点从页面中提取结构化数据。如果你想从一个URL列表中获得相同的结构化数据，这将非常有用。

<CodeGroup>

<BatchScrapeExtractPython />
<BatchScrapeExtractNode />
<BatchScrapeExtractCURL />

</CodeGroup>

### 响应
#### 同步

<BatchScrapeExtractOutput />


#### 异步

<BatchScrapeExtractAsyncOutput />