---
title: 欢迎使用 V1
description: 'Firecrawl 允许您将整个网站转换为 LLM 准备的 Markdown'
og:title: '欢迎使用 V1 | Firecrawl'
og:description: 'Firecrawl 允许您将整个网站转换为 LLM 准备的 Markdown'
---

import InstallationPython from '/snippets/v1/installation/python.mdx';
import InstallationNode from '/snippets/v1/installation/js.mdx';
import InstallationGo from '/snippets/v1/installation/go.mdx';
import InstallationRust from '/snippets/v1/installation/rust.mdx';
import ScrapePython from '/snippets/v1/scrape/base/python.mdx';
import ScrapeNode from '/snippets/v1/scrape/base/js.mdx';
import ScrapeGo from '/snippets/v1/scrape/base/go.mdx';
import ScrapeRust from '/snippets/v1/scrape/base/rust.mdx';
import ScrapeCURL from '/snippets/v1/scrape/base/curl.mdx';
import ScrapeResponse from '/snippets/v1/scrape/base/output.mdx';
import MapPython from '/snippets/v1/map/base/python.mdx';
import MapJavaScript from '/snippets/v1/map/base/js.mdx';
import MapGo from '/snippets/v1/map/base/go.mdx';
import MapRust from '/snippets/v1/map/base/rust.mdx';
import MapCURL from '/snippets/v1/map/base/curl.mdx';
import MapResponse from '/snippets/v1/map/base/output.mdx';
import CrawlWebSocketPythonBase from '/snippets/v1/crawl-websocket/base/python.mdx';
import CrawlWebSocketNodeBase from '/snippets/v1/crawl-websocket/base/js.mdx';
import ExtractCURL from '/snippets/v1/llm-extract/base/curl.mdx';
import ExtractPython from '/snippets/v1/llm-extract/base/python.mdx';
import ExtractNode from '/snippets/v1/llm-extract/base/js.mdx';
import ExtractOutput from '/snippets/v1/llm-extract/base/output.mdx';
import ExtractNoSchemaCURL from '/snippets/v1/llm-extract/no-schema/curl.mdx';
import ExtractNoSchemaOutput from '/snippets/v1/llm-extract/no-schema/output.mdx';
import CrawlWebhookCURL from '/snippets/v1/crawl-webhook/base/curl.mdx';

Firecrawl V1 来了！我们引入了更可靠且对开发者友好的 API。

以下是新增功能：

- `/scrape` 的输出格式。选择您希望输出的格式。
- 新的 [`/map` 端点](/features/map) 用于获取网页的大部分 URL。
- `/crawl/{id}` 状态的开发者友好 API。
- 所有计划的速率限制提高了一倍。
- [Go SDK](/sdks/go) 和 [Rust SDK](/sdks/rust)
- 团队支持
- 仪表板中的 API 密钥管理。
- `onlyMainContent` 现在默认为 `true`。
- `/crawl` webhook 和 websocket 支持。

## 抓取格式

您可以选择所需的输出格式。您可以指定多个输出格式。支持的格式有：

- Markdown (markdown)
- HTML (html)
- 原始 HTML (rawHtml)（无修改）
- 截图 (screenshot 或 screenshot@fullPage)
- 链接 (links)
- 提取 (extract) - 结构化输出

输出键将匹配您选择的格式。

<CodeGroup>

{' '}
<ScrapePython />

{' '}
<ScrapeNode />

{' '}
<ScrapeGo />

{' '}
<ScrapeRust />

{' '}
<ScrapeCURL />

</CodeGroup>

### 响应

SDK 将直接返回数据对象。cURL 将如下所示精确返回有效负载。

<ScrapeResponse />

## 介绍 /map（Alpha）

从单个 URL 到整个网站的映射的最简单方法。

### 使用方式

<CodeGroup>

<MapPython />
<MapJavaScript />
<MapGo />
<MapRust />
<MapCURL />

</CodeGroup>

### 响应

SDK 将直接返回数据对象。cURL 将如下所示精确返回有效负载。

<MapResponse />

## WebSockets

要使用 WebSockets 抓取网站，请使用“抓取 URL 并监视”方法。

<CodeGroup>

<CrawlWebSocketPythonBase />
<CrawlWebSocketNodeBase />

</CodeGroup>

## 提取格式

LLM 提取现在在 v1 中以 `extract` 格式提供。要从页面中提取结构化数据，您可以传递一个模式到端点，或者只提供一个提示。

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

输出：

<ExtractOutput />

### 无模式提取（新增）```md
现在，您可以通过仅向端点传递一个`prompt`来提取数据而无需模式。llm将选择数据的结构。

<CodeGroup>

<ExtractNoSchemaCURL />

</CodeGroup>

输出：

<ExtractNoSchemaOutput />

## 新的爬虫Webhook

现在，您可以向`/crawl`端点传递一个`webhook`参数。这将在开始、更新和完成爬取时向您指定的URL发送POST请求。

现在，每次爬取页面都会触发webhook，而不仅仅是在最后返回整个结果时。

<CrawlWebhookCURL />

### Webhook事件

现在有4种类型的事件：

- `crawl.started` - 当爬虫开始时触发。
- `crawl.page` - 为每个爬取的页面触发。
- `crawl.completed` - 当爬虫完成时触发，以通知您它已经完成。
- `crawl.failed` - 当爬虫失败时触发。

### Webhook响应

- `success` - 如果webhook成功爬取了页面。
- `type` - 发生的事件类型。
- `id` - 爬虫的ID。
- `data` - 抓取的数据（数组）。这只有在`crawl.page`事件中才会非空，如果页面成功抓取则包含1个项目。响应与`/scrape`端点的相同。
- `error` - 如果webhook失败，这将包含错误信息。

## 从V0迁移

> ⚠️ **弃用通知**：V0端点将在2025年4月1日弃用。请在此之前迁移到V1端点以确保服务不中断。

## /scrape端点

更新后的`/scrape`端点已重新设计，以提高可靠性和易用性。新的`/scrape`请求体结构如下：

```json
{
  "url": "<string>",
  "formats": ["markdown", "html", "rawHtml", "links", "screenshot", "json"],
  "includeTags": ["<string>"],
  "excludeTags": ["<string>"],
  "headers": { "<key>": "<value>" },
  "waitFor": 123,
  "timeout": 123
}
```

### 格式

现在，您可以选择希望输出的格式。您可以指定多个输出格式。支持的格式包括：

- Markdown (markdown)
- HTML (html)
- Raw HTML (rawHtml)（无修改）
- 截图 (screenshot或screenshot@fullPage)
- 链接 (links)
- JSON (json)

默认情况下，输出将仅包括Markdown格式。

### 新请求体的详细信息

下表概述了V1中`/scrape`端点请求体参数的变化。

| 参数                         | 变化          | 描述                                                                                               |
| ---------------------------- | ------------- | ---------------------------------------------------------------------------------------------------- |
| `onlyIncludeTags`            | 移动并重命名   | 移至根级别。并重命名为`includeTags`。                                                 |
| `removeTags`                 | 移动并重命名   | 移至根级别。并重命名为`excludeTags`。                                                |
| `onlyMainContent`            | 移动          | 移至根级别。默认值为`true`。                                                         |
| `waitFor`                    | 移动          | 移至根级别。                                                                        |
| `headers`                    | 移动          | 移至根级别。                                                                        |
| `parsePDF`                   | 移动          | 移至根级别。                                                                        |
| `extractorOptions`           | 无变化        |                                                                                                      |
| `timeout`                    | 无变化        |                                                                                                      |
| `pageOptions`                | 移除          | 不需要`pageOptions`参数。抓取选项已移至根级别。                                       |
| `replaceAllPathsWithAbsolutePaths` | 移除      | `replaceAllPathsWithAbsolutePaths`不再需要。所有路径现在都默认为绝对路径。       |
| `includeHtml`                | 移除          | 添加`"html"`到`formats`中。                                                      |
| `includeRawHtml`             | 移除          | 添加`"rawHtml"`到`formats`中。                                                      |
| `screenshot`                 | 移除          | 添加`"screenshot"`到`formats`中。                                                    |
| `fullPageScreenshot`         | 移除          | 添加`"screenshot@fullPage"`到`formats`中。                                            |
| `extractorOptions`           | 移除          | 使用`"extract"`格式并带有`extract`对象。                                              |
```新的 `extract` 格式在 [llm-extract](/features/extract) 部分中有所描述。

## /crawl 端点

我们还更新了 V1 版本的 `/crawl` 端点。请查看下面改进的请求体：

```json
{
  "url": "<string>",
  "excludePaths": ["<string>"],
  "includePaths": ["<string>"],
  "maxDepth": 2,
  "ignoreSitemap": true,
  "limit": 10,
  "allowBackwardLinks": true,
  "allowExternalLinks": true,
  "scrapeOptions": {
    // 与 /scrape 相同的选项
    "formats": ["markdown", "html", "rawHtml", "screenshot", "links"],
    "headers": { "<key>": "<value>" },
    "includeTags": ["<string>"],
    "excludeTags": ["<string>"],
    "onlyMainContent": true,
    "waitFor": 123
  }
}
```

### 关于新请求体的详细信息

下表概述了 V1 版本 `/crawl` 端点的请求体参数变化。

| 参数                 | 变更           | 描述                                                                       |
| -------------------- | -------------- | ------------------------------------------------------------------------- |
| `pageOptions`        | 重命名         | 重命名为 `scrapeOptions`。                                                    |
| `includes`           | 移动并重命名   | 移动到根级别。重命名为 `includePaths`。                                       |
| `excludes`           | 移动并重命名   | 移动到根级别。重命名为 `excludePaths`。                                       |
| `allowBackwardCrawling` | 移动并重命名 | 移动到根级别。重命名为 `allowBackwardLinks`。                                 |
| `allowExternalLinks` | 移动           | 移动到根级别。                                                             |
| `maxDepth`           | 移动           | 移动到根级别。                                                             |
| `ignoreSitemap`      | 移动           | 移动到根级别。                                                             |
| `limit`              | 移动           | 移动到根级别。                                                             |
| `crawlerOptions`     | 移除           | 不需要 `crawlerOptions` 参数。抓取选项已经移动到根级别。                         |
| `timeout`            | 移除           | 使用 `scrapeOptions` 中的 `timeout` 代替。                                    |